<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="用于日常笔记"><meta name="baidu-site-verification" content="31u13chEy5"><title>朴素贝叶斯法原理及实现 | Netycc's blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><script async="" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = 'https://hm.baidu.com/hm.js?' + '83d60cd5e215de54f53db5b26853c623';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
  </script></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">朴素贝叶斯法原理及实现</h1><a id="logo" href="/.">Netycc's blog</a><p class="description">每天进步一点点，吃吃喝喝的single dog.</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/timeline"><i class="fa fa-history"> 时间线</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">朴素贝叶斯法原理及实现</h1><div class="post-meta">Oct 17, 2018<span> | </span><span class="category"><a href="/categories/学习笔记/">学习笔记</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 1.4k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i><span class="post-count"> 6</span><span class="post-meta-item-text"> 分钟</span></span></span></div><a class="disqus-comment-count" href="/2018/10/17/朴素贝叶斯法原理及实现/#vcomment"><span class="valine-comment-count" data-xid="/2018/10/17/朴素贝叶斯法原理及实现/"></span><span> 条评论</span></a><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#前言"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#朴素贝叶斯法的学习与分类"><span class="toc-number">2.</span> <span class="toc-text">朴素贝叶斯法的学习与分类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#基本方法"><span class="toc-number">2.1.</span> <span class="toc-text">基本方法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#朴素贝叶斯法的参数估计"><span class="toc-number">3.</span> <span class="toc-text">朴素贝叶斯法的参数估计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#极大似然估计"><span class="toc-number">3.1.</span> <span class="toc-text">极大似然估计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#学习与分类算法"><span class="toc-number">3.2.</span> <span class="toc-text">学习与分类算法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#朴素贝叶斯算法在digits数据集上的实现"><span class="toc-number">4.</span> <span class="toc-text">朴素贝叶斯算法在digits数据集上的实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#code"><span class="toc-number">4.1.</span> <span class="toc-text">code</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#结果"><span class="toc-number">4.2.</span> <span class="toc-text">结果</span></a></li></ol></li></ol></div></div><div class="post-content"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>朴素贝叶斯法是基于贝叶斯定理与特征条件独立假设的分类方法。对于给定的训练数据集，首先基于特征条件独立假设学习输入/输出的联合概率分布；然后基于此模型，对于给定的输入x，利用贝叶斯定理求出后验概率最大的输出y。朴素贝叶斯法实现简单，学习与预测的效率都很高，是一种常用的方法。</p>
<h2 id="朴素贝叶斯法的学习与分类"><a href="#朴素贝叶斯法的学习与分类" class="headerlink" title="朴素贝叶斯法的学习与分类"></a>朴素贝叶斯法的学习与分类</h2><h3 id="基本方法"><a href="#基本方法" class="headerlink" title="基本方法"></a>基本方法</h3><p>设输入空间$\mathcal{X}\subseteq R_n$为n维向量的集合，输出空间为类标记集合$\mathcal{Y}=\{c_1,c_2,…,c_k\}$.输入为特征向量$x\in \mathcal{X}$，输出为类标记$y\in \mathcal{Y}$.X是定义在输入空间$\mathcal{X}$上的随机向量，Y是定义在输出空间$\mathcal{Y}$上的随机变量。$P(X,Y)$是X和Y的联合概率分布。训练数据集$$T=\{(x_1,y_1),(x_2,y_2),…,(x_N,y_N)\}$$由<em>$P(X,Y)$独立同分布</em>产生。</p>
<p>朴素贝叶斯法通过训练数据集学习联合概率分布$P(X,Y)$。具体地，学习以下<em>先验概率分布</em>及<em>条件概率分布</em>。先验概率分布$$P(Y=c_k)，k=1,2,…,K$$条件概率分布（后验概率分布）$$P(X=x|Y=c_k)=P(X^{(1)}=x^{(1)},…,X^{(n)}=x^{(n)}|Y=c_k)$$于是学习到联合概率分布$P(X,Y)$.</p>
<p>条件概率分布$P(X=x|Y=c_k)$有指数级数量的参数，其估计实际是不可行的。事实上，假设$x^{(j)}$可取值有$S_j$个，$j=1,2,…,n$，Y可取值有K个，那么参数个数为$$K\prod_{j=1}^{n}S_j$$</p>
<p>朴素贝叶斯法对条件概率分布作了<em>条件独立性</em>的假设。由于这是一个较强的假设，朴素贝叶斯法也由此得名。朴素贝叶斯法实际上学习到生成数据的机制，所以属于生成模型。条件独立假设等于是说用于分类的特征在类确定的条件下都是条件独立的。这一假设使朴素贝叶斯法变得简单，但有时会牺牲一定的分类准确率。</p>
<p>朴素贝叶斯法分类的基本公式：$$P(Y=c_k|X=x)=\frac{P(Y=c_k)\prod_j P(X^{(j)}=x^{(j)}|Y=c_k)}{\sum_k P(Y=c_k) \prod_j (X^{(j)}=x^{(j)}|Y=c_k)}$$</p>
<p>朴素贝叶斯法分类器可表示为$$y=f(x)=arg \max_{c_k} P(Y=c_k) \prod_j P(X^{(j)}=x^{(j)}|Y=c_k)$$</p>
<h2 id="朴素贝叶斯法的参数估计"><a href="#朴素贝叶斯法的参数估计" class="headerlink" title="朴素贝叶斯法的参数估计"></a>朴素贝叶斯法的参数估计</h2><h3 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h3><p>在朴素贝叶斯法中，学习意味着估计$P(Y=c_k)$和$P(X^{(j)}=x^{(j)}|Y=c_k)$.可以应用极大似然估计法估计相应的概率。<em>先验概率</em>$P(Y=c_k)$的极大似然估计是$$P(Y=c_k)=\frac {\sum_{i=1}^{N} I(y_i=c_k)} {N}，k=1,2,…,K$$设第$j$个特征$x^{(j)}$可能取值的集合为$\{a_{j1},a_{j2},…,a_{jS_j}\}$，条件概率$P(X^{j}=a_{jl}||Y=c_k)$的极大似然估计是$$P(x^{(j)}=a_{jl}|Y=c_k)=\frac{\sum_{i=1}^{N} I(x_i^{(j)}=a_{jl},y_i=c_k)}{\sum_{i=1}^{N}I(y_i=c_k)}\\j=1,2,…,n;l=1,2,…,S_j;k=1,2,…,K$$式中，$x_i^{(j)}$是第$i$个样本的第$j$个特征；$a_{jl}$是第$j$个特征可能取的第$l$个值：$I$为指示函数。</p>
<h3 id="学习与分类算法"><a href="#学习与分类算法" class="headerlink" title="学习与分类算法"></a>学习与分类算法</h3><blockquote>
<p>(朴素贝叶斯算法)<br>输入：训练数据$T=\{(x_1,y_1),(x_2,y_2),…,(x_N,y_N)\}$，其中$x_i=(x_i^{(1)},x_i^{(2)},…,x_i^{(n)})$，$x_i^{(j)}$是第$i$个样本的第$j$个特征，$x_i^{(j)}\in \{a_{j1},a_{j2},…,a_{jS_j}\}$，$a_{jl}$是第$j$个特征可能取的第$l$个值，$j=1,2,…,n$，$l=1,2,…,S_j$，$y_i\in \{c1,c2,…,c_k\}$；实例$x$；<br>输出：实例$x$的分类</p>
<ol>
<li>计算先验概率及条件概率$$P(Y=c_k)=\frac {\sum_{i=1}^{N} I(y_i=c_k)}{N},k=1,2,…,K\\P(X^{(j)}=a_{jl}|Y=c_k)=\frac {\sum_{i=1}^{(j)}I(x_i^{(j)}=a_{jl},y_i=c_k)}{\sum_{i=1}^{N}I(y_i=c_k)}\\j=1,2,…,n；l=1,2,…,S_j；k=1,2,…,K$$</li>
<li>对于给定的实例$x=(x^{(1)},x^{(2)},…,x^{(n)})^T$，计算$$P(Y=c_k)\prod_{j=1}^{n}P(X^{(j)}=X^{(j)}|Y=c_k),k=1,2,…,K$$</li>
<li>确定实例$x$的类$$y=arg \max_{c_k} P(Y=c_k)\prod_{j=1}^{n}P(X^{(j)}=x^{(j)}|Y=c_k)$$</li>
</ol>
</blockquote>
<h2 id="朴素贝叶斯算法在digits数据集上的实现"><a href="#朴素贝叶斯算法在digits数据集上的实现" class="headerlink" title="朴素贝叶斯算法在digits数据集上的实现"></a>朴素贝叶斯算法在digits数据集上的实现</h2><h3 id="code"><a href="#code" class="headerlink" title="code"></a>code</h3><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.datasets import load_digits</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_digits</span><span class="params">()</span></span><span class="symbol">:</span></span><br><span class="line">    digits = load_digits()</span><br><span class="line">    data = np.zeros([len(digits.data), len(digits.data[<span class="number">0</span>])])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(digits.data))<span class="symbol">:</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> range(len(digits.data[<span class="number">0</span>]))<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">if</span> digits.data[i][t] &gt; <span class="number">0</span><span class="symbol">:</span></span><br><span class="line">                data[i][t] = <span class="number">1</span></span><br><span class="line">            <span class="symbol">else:</span></span><br><span class="line">                data[i][t] = <span class="number">0</span></span><br><span class="line">    X_train, X_test, y_train, y_test = train_test_split(data,np.array(digits.target) , test_size=<span class="number">0</span>.<span class="number">25</span>,random_state=<span class="number">33</span>)</span><br><span class="line">    <span class="keyword">return</span> X_train, X_test, y_train, y_test</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Naive_Bayes</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(<span class="keyword">self</span>,X,Y)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.P_Yc=np.zeros(<span class="number">10</span>)<span class="comment">#保存P(Y=c_k)</span></span><br><span class="line">        <span class="keyword">self</span>.I_Yc=np.zeros(<span class="number">10</span>)<span class="comment">#保存I(Y_i=c_k)</span></span><br><span class="line">        <span class="keyword">self</span>.I_XaYc=np.zeros((len(X[<span class="number">0</span>]),len([<span class="number">0</span>,<span class="number">1</span>]),<span class="number">10</span>))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(Y))<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">self</span>.I_Yc[Y[i]]+=<span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> t <span class="keyword">in</span> range(len(X[<span class="number">0</span>]))<span class="symbol">:</span></span><br><span class="line">                <span class="keyword">self</span>.I_XaYc[t][ int(X[i][t]) ][Y[i]]+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">self</span>.P_Yc=[i/sum(<span class="keyword">self</span>.I_Yc) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="keyword">self</span>.I_Yc]</span><br><span class="line">        <span class="comment"># 第一项特征的数量，特征值的种类数量，分类的种类</span></span><br><span class="line">        <span class="keyword">self</span>.P_XaYc=np.zeros((len(X[<span class="number">0</span>]),len([<span class="number">0</span>,<span class="number">1</span>]),<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(X[<span class="number">0</span>]))<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">for</span> t <span class="keyword">in</span> range(len([<span class="number">0</span>,<span class="number">1</span>]))<span class="symbol">:</span></span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">10</span>)<span class="symbol">:</span></span><br><span class="line">                    <span class="keyword">self</span>.P_XaYc[i][t][j]=<span class="keyword">self</span>.I_XaYc[i][t][j]/<span class="keyword">self</span>.I_Yc[j]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(<span class="keyword">self</span>,x)</span></span><span class="symbol">:</span></span><br><span class="line">        score=np.zeros(<span class="number">10</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>)<span class="symbol">:</span></span><br><span class="line">            a=<span class="keyword">self</span>.P_Yc[i]</span><br><span class="line">            <span class="keyword">for</span> t <span class="keyword">in</span> range(len(x))<span class="symbol">:</span></span><br><span class="line">                a*=<span class="keyword">self</span>.P_XaYc[t][int(x[t])][i]</span><br><span class="line">            score[i]=a</span><br><span class="line">        <span class="keyword">return</span> score.argmax()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name_<span class="number">_</span> == <span class="string">'__main__'</span><span class="symbol">:</span></span><br><span class="line">    <span class="comment"># print(get_digits())</span></span><br><span class="line">    X_train, X_test, Y_train, y_test= get_digits()</span><br><span class="line">    nb=Naive_Bayes()</span><br><span class="line">    nb.train(X_train,Y_train)</span><br><span class="line">    t_num=<span class="number">0</span></span><br><span class="line">    print(<span class="string">"*"</span>*<span class="number">10</span>,<span class="string">"预测过程"</span>,<span class="string">"*"</span>*<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(y_test))<span class="symbol">:</span></span><br><span class="line">        <span class="keyword">if</span> nb.predict(X_test[i])==y_test[i]<span class="symbol">:</span></span><br><span class="line">            t_num+=<span class="number">1</span></span><br><span class="line">        print(<span class="string">"case"</span>,i,<span class="string">"，预测值："</span>,nb.predict(X_test[i]),<span class="string">"，真实值："</span>,y_test[i],<span class="string">"预测结果:"</span>,nb.predict(X_test[i])==y_test[i])</span><br><span class="line">    print(<span class="string">"*"</span>*<span class="number">10</span>,<span class="string">"预测结果"</span>,<span class="string">"*"</span>*<span class="number">10</span>)</span><br><span class="line">    print(<span class="string">"准确率："</span>,t_num/len(y_test))</span><br></pre></td></tr></table></figure>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p><img src="/2018/10/17/朴素贝叶斯法原理及实现/QQ20181018-080645.png" alt="朴素贝叶斯法预测结果"></p>
</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>netycc</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/2018/10/17/朴素贝叶斯法原理及实现/">https://netycc.com/2018/10/17/朴素贝叶斯法原理及实现/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0 CN</a> 许可协议。转载请注明出处！</li></ul></div><br><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a class="article-share-link" data-url="https://netycc.com/2018/10/17/朴素贝叶斯法原理及实现/" data-id="cjpt5mrb0001s3382tmhfe0yd" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAN4AAADeCAAAAAB3DOFrAAACwElEQVR42u3aQXLCMAwFUO5/abrtDGC+pAhYvKw6rUn80hnLfPl2i6/7w/Xq9///moy5F6/bxoWHh4c3nnqVcR75+PvHp59nlTzl5SvAw8PDW+O9esD51r1P5aTkzm8seHh4eD/AOy/c+aeS8fmd8fDw8H6fl2yUkzskGcIXCgMeHh5ewKsu2efpnsfPt9orWQseHh7eQhfpd35e6e/h4eHhjbvq+YGAaGtbLCcXHDLAw8PDW+DlC271WFUvup0fusLDw8P7DK8X4OZTb8av8ZGFalCCh4eHN+Hly271mGm1lTVppL2cOR4eHt4ar9fCz7fI8yMCySt48kQ8PDy8BV51q5os/XmbqndooNwMw8PDw1vg5Q+uhg692DeJdPMxeHh4eNfyqhOatLWqEcMFqz0eHh7eMi8vDEmcWi0nefEovGg8PDy8NV615d8rGxcv+seoovwxPDw8vCIv3/j2gtR78eoVoSfj8fDw8NZ4eSgwb24lz6qOaZ5KwMPDw+vPJGrSz8OFvNhM4t3o2wMeHh7egJcHEL3v+Pnxgjz8zSNjPDw8vG1eHsLm29xqwHFtYwwPDw9vg7fRLZos5ZMo5M198PDw8JZ5eRhxu+jqlahzgw0PDw9vg9c7zDQZPwkpkgMHhS4cHh4eXouXN8B6zaqrgoz8WW/qHh4eHt5FvF40UN0WJ1PPX0dhc4+Hh4f3cd78EFX1Bc0bbHh4eHif4eWYaohQDUGqr6bwXQEPDw9vzLsXr/ydVQ8TzP9LUQMMDw8Pb8y76tb5cn9+BfmYanyMh4eHdy0vKQbV1n7eWss/1SwMeHh4eGu8+aI8ORQ1qV2FBhgeHh7el3jJ8p3HxPMgI0qp8fDw8L7KO080j4N7eUm5/ODh4eGt8ZKpJEt2tZDkxaC63cfDw8Pb4/W+8OcLfbV49GLc0YWHh4eX8v4A0Y+mS/evu14AAAAASUVORK5CYII=">分享</a><div class="tags"><a href="/tags/机器学习/">机器学习</a><a href="/tags/统计学习方法/">统计学习方法</a><a href="/tags/python/">python</a><a href="/tags/朴素贝叶斯/">朴素贝叶斯</a></div><div class="post-nav"><a class="pre" href="/2018/10/19/决策树的原理及实现/">决策树的原理及实现</a><a class="next" href="/2018/10/16/K近邻算法的原理及实现/">K近邻算法的原理及实现</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'true' == true ? true : false;
var verify = 'true' == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'dCzd3ozN5OlrLCT1FcrMc8D7-gzGzoHsz',
  appKey:'UmIi39gBjdh1Aria4ssShR31',
  placeholder:'欢迎讨论~',
  avatar:'identicon',
  guest_info:guest_info,
  pageSize:'10'
})</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/刷题记录/">刷题记录</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/学习笔记/">学习笔记</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术技巧/">技术技巧</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/课设记录/">课设记录</a><span class="category-list-count">2</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/linux/" style="font-size: 15px;">linux</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/感知机/" style="font-size: 15px;">感知机</a> <a href="/tags/Jekyll/" style="font-size: 15px;">Jekyll</a> <a href="/tags/blog/" style="font-size: 15px;">blog</a> <a href="/tags/java/" style="font-size: 15px;">java</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/笔试/" style="font-size: 15px;">笔试</a> <a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/K近邻/" style="font-size: 15px;">K近邻</a> <a href="/tags/LeetCode/" style="font-size: 15px;">LeetCode</a> <a href="/tags/深度学习/" style="font-size: 15px;">深度学习</a> <a href="/tags/TensorFlow/" style="font-size: 15px;">TensorFlow</a> <a href="/tags/RNN/" style="font-size: 15px;">RNN</a> <a href="/tags/LSTM/" style="font-size: 15px;">LSTM</a> <a href="/tags/ssh配置/" style="font-size: 15px;">ssh配置</a> <a href="/tags/统计学习方法/" style="font-size: 15px;">统计学习方法</a> <a href="/tags/显卡驱动配置/" style="font-size: 15px;">显卡驱动配置</a> <a href="/tags/决策树/" style="font-size: 15px;">决策树</a> <a href="/tags/贝叶斯定理/" style="font-size: 15px;">贝叶斯定理</a> <a href="/tags/单词纠错器/" style="font-size: 15px;">单词纠错器</a> <a href="/tags/Bert/" style="font-size: 15px;">Bert</a> <a href="/tags/WordEmbedding/" style="font-size: 15px;">WordEmbedding</a> <a href="/tags/cosine/" style="font-size: 15px;">cosine</a> <a href="/tags/朴素贝叶斯/" style="font-size: 15px;">朴素贝叶斯</a> <a href="/tags/正则表达式/" style="font-size: 15px;">正则表达式</a> <a href="/tags/osx/" style="font-size: 15px;">osx</a> <a href="/tags/ssr/" style="font-size: 15px;">ssr</a> <a href="/tags/proxychains/" style="font-size: 15px;">proxychains</a> <a href="/tags/NLP/" style="font-size: 15px;">NLP</a> <a href="/tags/HMM/" style="font-size: 15px;">HMM</a> <a href="/tags/CWS/" style="font-size: 15px;">CWS</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/12/17/利用Bayes定理构建单词纠错器/">利用Bayes定理构建单词纠错器</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/05/利用bert构建词向量并计算相似度/">利用Bert构建词向量并计算相似度</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/04/正则表达式总结/">正则表达式记录</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/02/LeetCode-1-3/">[LeetCode]Problem 1-3</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/17/TensorFlow学习手册（四）/">TensorFlow学习手册（四）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/16/通过proxychains在终端使用ss代理/">通过proxychains在终端使用ss代理</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/14/安装cuda9-0和cudnn7-4以及tensorflow-gpu-1-11-0/">安装cuda9.0和cudnn7.4以及tensorflow-gpu==1.11.0</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/14/TensorFlow学习手册（三）/">TensorFlow学习手册（三）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/10/TensorFlow学习手册（二）/">TensorFlow学习手册（二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/09/TensorFlow学习手册（一）/">TensorFlow学习手册（一）</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://www.haomwei.com/technology/maupassant-hexo.html" title="博客模板" target="_blank">博客模板</a><ul></ul><a href="https://hyxxsfwy.github.io/2016/01/15/Hexo-Markdown-%E7%AE%80%E6%98%8E%E8%AF%AD%E6%B3%95%E6%89%8B%E5%86%8C/" title="HEXO markdown简明语法" target="_blank">HEXO markdown简明语法</a><ul></ul><a href="http://www.mohu.org/info/symbols/symbols.htm" title="mathjax使用的查阅手册" target="_blank">mathjax使用的查阅手册</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">Netycc's blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a><br/><span id="busuanzi_container_site_uv">本站访客数<span id="busuanzi_value_site_uv"></span>人次</span></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
extensions: ["tex2jax.js"],
jax: ["input/TeX", "output/HTML-CSS"],
tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: true
},
    "HTML-CSS": { fonts: ["TeX"] }
  });</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>
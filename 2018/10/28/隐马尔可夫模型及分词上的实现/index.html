<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="用于日常笔记"><meta name="baidu-site-verification" content="31u13chEy5"><title>隐马尔可夫模型及分词上的实现 | Netycc's blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = 'https://hm.baidu.com/hm.js?' + '83d60cd5e215de54f53db5b26853c623';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
  </script></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">隐马尔可夫模型及分词上的实现</h1><a id="logo" href="/.">Netycc's blog</a><p class="description">每天进步一点点，吃吃喝喝的single dog.</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/timeline"><i class="fa fa-history"> 时间线</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">隐马尔可夫模型及分词上的实现</h1><div class="post-meta">Oct 28, 2018<span> | </span><span class="category"><a href="/categories/学习笔记/">学习笔记</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 2.2k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i><span class="post-count"> 10</span><span class="post-meta-item-text"> 分钟</span></span></span></div><a class="disqus-comment-count" href="/2018/10/28/隐马尔可夫模型及分词上的实现/#vcomment"><span class="valine-comment-count" data-xid="/2018/10/28/隐马尔可夫模型及分词上的实现/"></span><span> 条评论</span></a><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#前言"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#隐马尔可夫模型的基本概念"><span class="toc-number">2.</span> <span class="toc-text">隐马尔可夫模型的基本概念</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#隐马尔可夫模型的定义"><span class="toc-number">2.1.</span> <span class="toc-text">隐马尔可夫模型的定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#观测序列的生成过程"><span class="toc-number">2.2.</span> <span class="toc-text">观测序列的生成过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#隐马尔可夫模型的3个基本问题"><span class="toc-number">2.3.</span> <span class="toc-text">隐马尔可夫模型的3个基本问题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HMM在统计分词中的实现"><span class="toc-number">3.</span> <span class="toc-text">HMM在统计分词中的实现</span></a></li></ol></div></div><div class="post-content"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近开始看自然语言处理的实战部分，看到了<strong>统计分词</strong>那里，统计分词用的模型是<strong>隐马尔可夫模型</strong>(HMM)，这里先介绍一下这个模型，它是可用于标注问题的统计学模型，描述由隐藏的马尔可夫链随机生成观测序列的过程，属于<strong>生成模型</strong>。</p>
<h2 id="隐马尔可夫模型的基本概念"><a href="#隐马尔可夫模型的基本概念" class="headerlink" title="隐马尔可夫模型的基本概念"></a>隐马尔可夫模型的基本概念</h2><h3 id="隐马尔可夫模型的定义"><a href="#隐马尔可夫模型的定义" class="headerlink" title="隐马尔可夫模型的定义"></a>隐马尔可夫模型的定义</h3><blockquote>
<p>定义10.1(隐马尔可夫模型)<br>隐马尔可夫模型是关于时序的概率模型，描述由一个隐藏的马尔科夫链随机生成不可观测的状态随机序列，再由各个状态生成一个观测而产生观测随机序列的过程。隐藏的马尔可夫链随机生成的状态的序列，称为<strong>状态序列</strong>；每个状态生成一个观测，而由此产生的观测的随机序列，称为<strong>观测序列</strong>。序列的每一个位置又可以看作是一个时刻。</p>
</blockquote>
<p>隐马尔可夫模型由初始概率分布、状态转移概率分布以及观测概率分布确定。隐马尔可夫模型的形式定义如下：<br>设$Q$是所有可能的状态的集合，$V$是所有可能的观测的集合。$$Q=\{q_1,q_2,…,q_N\}，V=\{v_1,v_2,…,v_M\}$$其中，$N$是可能的状态数，$M$是可能的观测数.以下$I$是长度为$T$的状态序列，$O$是对应的观测序列。$$I=(i_1,i_2,…,i_T)，O=(o_1,o_2,…,o_T)$$$A$是状态转移概率矩阵.$$A=[a_{ij}]_{N\times N}\tag{10.1}$$</p>
<p>其中，$$a_{ij}=P(i_{t+1}=q_j|i_t=q_i)，i=1,2,…,N;j=1,2,…,N\tag{10.2}$$是在时刻t处于$q_i$的条件下在时刻$t+1$转移到状态$q_j$的概率。<br>$B$是观测概率矩阵：$$B=[b_j(k)]_{N\times M}\tag{10.3}$$其中，$$b_j(k)=P(o_t=v_k|i_t=q_j)，k=1,2,…,M;j=1,2,…,N\tag{10.4}$$是在时刻$t$处于状态$q_j$的条件下生成观测$v_k$的概率。<br>$\pi$是初始状态概率向量：$$\pi=(\pi_i)\tag{10.5}$$其中，$$\pi_i=P(i_1=q_i)，i=1,2,…,N\tag{10.6}$$是时刻$t=1$处于状态$q_i$的概率。<br>隐马尔可夫模型由初始状态概率向量$\pi$、状态转移概率矩阵$A$和观测概率矩阵$B$决定。$\pi$和$A$决定状态序列，$B$决定观测序列。因此，隐马尔可夫模型$\lambda$可以用三元符号表示，即$$\lambda=(A,B,\pi)\tag{10.7}$$<br>$A,B,\pi$称为隐马尔可夫模型的三要素。<br>状态转移概率矩阵$A$与初始状态概率向量$\pi$确定了隐藏的马尔可夫链，生成不可观测的状态序列。观测概率矩阵$B$确定了如何从状态生成观测，与状态序列综合确定了如何产生观测序列。<br>从定义上可知，隐马尔可夫模型作了两个基本假设：</p>
<ol>
<li>齐次马尔可夫性假设，即假设隐藏的马尔可夫链在任意时刻$t$的状态只依赖于其前一时刻的状态，与其他时刻的状态及观测无关，也与时刻$t$无关。$$P(i_t|i_{t-1},o_{t-1},…,i_1,o_1)=P(i_t|i_{t-1})，t=1,2,…,T\tag{10.8}$$</li>
<li>观测独立性假设，即假设任意时刻的观测只依赖于该时刻的马尔可夫链的状态，与其他观测及状态无关。$$P(o_t|i_T,o_T,i_{T-1},o_{T-1},…,i_{t+1},o_{t+1},i_t,i_{t-1},o_{t-1},…,i_1,o_1)=P(o_t|i_t)\tag{10.9}$$</li>
</ol>
<p>隐马尔可夫模型可以用于标注，这时状态对应着标记。标注问题是给定观测的序列预测其对应的标记序列。可以假设标注问题的数据是由隐马尔可夫模型生成的。这样我们可以利用隐马尔可夫模型的学习与预测算法进行标注。</p>
<h3 id="观测序列的生成过程"><a href="#观测序列的生成过程" class="headerlink" title="观测序列的生成过程"></a>观测序列的生成过程</h3><p>根据隐马尔可夫模型定义，可以将一个长度为$T$的观测序列$O=(O_1,O_2,…,O_T)$的生成过程描述如下：</p>
<blockquote>
<p>算法10.1（观测序列的生成）<br>输入：隐马尔可夫模型$\lambda=(A,B,\pi)$，观测序列长度为$T$；<br>输出：观测序列$O=(o_1,o_2,…,o_T)$<br>(1)按照初始状态分布$\pi$产生状态$i_1$<br>(2)令$t=1$<br>(3)按照状态$i_t$的观测概率分布$b_{i_t}(k)$生成$o_t$<br>(4)按照状态$i_t$的状态转移概率分布$\{a_{i_ti_{t+1}}\}$产生状态$i_t+1，i_t+1=1,2,…,N$<br>(5)令$t=t+1$；如果$t&lt;T$，转步(3)；否则，终止。</p>
</blockquote>
<h3 id="隐马尔可夫模型的3个基本问题"><a href="#隐马尔可夫模型的3个基本问题" class="headerlink" title="隐马尔可夫模型的3个基本问题"></a>隐马尔可夫模型的3个基本问题</h3><p>隐马尔可夫模型有三个基本问题：</p>
<ol>
<li>概率计算问题。给定模型$\lambda=(A,B,\pi)$和观测序列$O=(o_1,o_2,…,o_T)$，计算在模型$\lambda$下观测序列$O$出现的概率$P(O|\lambda)$.</li>
<li>学习问题。已知观测序列$O=(o_1,o_2,…,o_T)$，估计模型$\lambda=(A,B,\pi)$参数，使得在该模型下观测序列概率$P(O|\lambda)$最大。即用极大似然估计的方法估计参数。</li>
<li>预测问题。已知模型$\lambda=(A,B,\pi)$和观测序列$O=(o_1,o_2,…,o_T)$，求对给定观测序列条件概率$P(I|O)$最大的状态序列$I=(i_1,i_2,…,i_T)$。即给定观测序列，求最有可能的对应的状态序列。</li>
</ol>
<blockquote>
<p>未完待续</p>
</blockquote>
<h2 id="HMM在统计分词中的实现"><a href="#HMM在统计分词中的实现" class="headerlink" title="HMM在统计分词中的实现"></a>HMM在统计分词中的实现</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br></pre></td><td class="code"><pre><span class="line">class HMM(object):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        import os</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 主要是用于存取算法中间结果，不用每次都训练模型</span></span><br><span class="line">        self.model_file = './data/hmm_model.pkl'</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 状态值集合</span></span><br><span class="line">        self.state_list = ['B', 'M', 'E', 'S']</span><br><span class="line">        <span class="comment"># 参数加载,用于判断是否需要重新加载model_file</span></span><br><span class="line">        self.load_para = False</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 用于加载已计算的中间结果，当需要重新训练时，需初始化清空结果</span></span><br><span class="line">    def try_load_model(self, trained):</span><br><span class="line">        if trained:</span><br><span class="line">            import pickle</span><br><span class="line">            <span class="keyword">with</span> <span class="keyword">open</span>(self.model_file, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">                self.A_dic = pickle.load(f)</span><br><span class="line">                self.B_dic = pickle.load(f)</span><br><span class="line">                self.Pi_dic = pickle.load(f)</span><br><span class="line">                self.load_para = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 状态转移概率（状态-&gt;状态的条件概率）</span></span><br><span class="line">            self.A_dic = &#123;&#125;</span><br><span class="line">            <span class="comment"># 发射概率（状态-&gt;词语的条件概率）</span></span><br><span class="line">            self.B_dic = &#123;&#125;</span><br><span class="line">            <span class="comment"># 状态的初始概率</span></span><br><span class="line">            self.Pi_dic = &#123;&#125;</span><br><span class="line">            self.load_para = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算转移概率、发射概率以及初始概率</span></span><br><span class="line">    <span class="keyword">def</span> train(<span class="keyword">self</span>, <span class="keyword">path</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 重置几个概率矩阵</span></span><br><span class="line">        self.try_load_model(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 统计状态出现次数，求p(o)</span></span><br><span class="line">        Count_dic = &#123;&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 初始化参数</span></span><br><span class="line">        <span class="keyword">def</span> init_parameters():</span><br><span class="line">            <span class="keyword">for</span> state <span class="keyword">in</span> self.state_list:</span><br><span class="line">                self.A_dic[state] = &#123;s: <span class="number">0.0</span> <span class="keyword">for</span> s <span class="keyword">in</span> self.state_list&#125;</span><br><span class="line">                self.Pi_dic[state] = <span class="number">0.0</span></span><br><span class="line">                self.B_dic[state] = &#123;&#125;</span><br><span class="line"></span><br><span class="line">                Count_dic[state] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> makeLabel(<span class="built_in">text</span>):</span><br><span class="line">            out_text = []</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">len</span>(<span class="built_in">text</span>) == <span class="number">1</span>:</span><br><span class="line">                out_text.append(<span class="string">'S'</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                out_text += [<span class="string">'B'</span>] + [<span class="string">'M'</span>] * (<span class="keyword">len</span>(<span class="built_in">text</span>) - <span class="number">2</span>) + [<span class="string">'E'</span>]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> out_text</span><br><span class="line"></span><br><span class="line">        init_parameters()</span><br><span class="line">        line_num = <span class="number">-1</span></span><br><span class="line">        <span class="comment"># 观察者集合，主要是字以及标点等</span></span><br><span class="line">        words = <span class="keyword">set</span>()</span><br><span class="line">        <span class="keyword">with</span> <span class="keyword">open</span>(<span class="keyword">path</span>, <span class="keyword">encoding</span>=<span class="string">'utf8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                line_num += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                line = line.strip()</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> line:</span><br><span class="line">                    continue</span><br><span class="line"></span><br><span class="line">                word_list = [i <span class="keyword">for</span> i <span class="keyword">in</span> line <span class="keyword">if</span> i != <span class="string">' '</span>]</span><br><span class="line">                words |= <span class="keyword">set</span>(word_list)  <span class="comment"># 更新字的集合</span></span><br><span class="line"></span><br><span class="line">                linelist = line.split()</span><br><span class="line"></span><br><span class="line">                line_state = []</span><br><span class="line">                <span class="keyword">for</span> w <span class="keyword">in</span> linelist:</span><br><span class="line">                    line_state.extend(makeLabel(w))</span><br><span class="line"></span><br><span class="line">                assert <span class="keyword">len</span>(word_list) == <span class="keyword">len</span>(line_state)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">for</span> k, v <span class="keyword">in</span> enumerate(line_state):</span><br><span class="line">                    Count_dic[v] += <span class="number">1</span></span><br><span class="line">                    <span class="keyword">if</span> k == <span class="number">0</span>:</span><br><span class="line">                        self.Pi_dic[v] += <span class="number">1</span>  <span class="comment"># 每个句子的第一个字的状态，用于计算初始状态概率</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        self.A_dic[line_state[k - <span class="number">1</span>]][v] += <span class="number">1</span>  <span class="comment"># 计算转移概率</span></span><br><span class="line">                        self.B_dic[line_state[k]][word_list[k]] = \</span><br><span class="line">                            self.B_dic[line_state[k]].get(word_list[k], <span class="number">0</span>) + <span class="number">1.0</span>  <span class="comment"># 计算发射概率</span></span><br><span class="line"></span><br><span class="line">        self.Pi_dic = &#123;k: v * <span class="number">1.0</span> / line_num <span class="keyword">for</span> k, v <span class="keyword">in</span> self.Pi_dic.items()&#125;</span><br><span class="line">        self.A_dic = &#123;k: &#123;k1: v1 / Count_dic[k] <span class="keyword">for</span> k1, v1 <span class="keyword">in</span> v.items()&#125;</span><br><span class="line">                      <span class="keyword">for</span> k, v <span class="keyword">in</span> self.A_dic.items()&#125;</span><br><span class="line">        <span class="comment"># 加1平滑</span></span><br><span class="line">        self.B_dic = &#123;k: &#123;k1: (v1 + <span class="number">1</span>) / Count_dic[k] <span class="keyword">for</span> k1, v1 <span class="keyword">in</span> v.items()&#125;</span><br><span class="line">                      <span class="keyword">for</span> k, v <span class="keyword">in</span> self.B_dic.items()&#125;</span><br><span class="line">        <span class="comment"># 序列化</span></span><br><span class="line">        <span class="keyword">import</span> pickle</span><br><span class="line">        <span class="keyword">with</span> <span class="keyword">open</span>(self.model_file, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            pickle.dump(self.A_dic, f)</span><br><span class="line">            pickle.dump(self.B_dic, f)</span><br><span class="line">            pickle.dump(self.Pi_dic, f)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">self</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> viterbi(<span class="keyword">self</span>, <span class="built_in">text</span>, states, start_p, trans_p, emit_p):</span><br><span class="line">        V = [&#123;&#125;]</span><br><span class="line">        <span class="keyword">path</span> = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> y <span class="keyword">in</span> states:</span><br><span class="line">            V[<span class="number">0</span>][y] = start_p[y] * emit_p[y].get(<span class="built_in">text</span>[<span class="number">0</span>], <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">path</span>[y] = [y]</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="keyword">range</span>(<span class="number">1</span>, <span class="keyword">len</span>(<span class="built_in">text</span>)):</span><br><span class="line">            V.append(&#123;&#125;)</span><br><span class="line">            newpath = &#123;&#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 检验训练的发射概率矩阵中是否有该字</span></span><br><span class="line">            neverSeen = <span class="built_in">text</span>[t] <span class="keyword">not</span> <span class="keyword">in</span> emit_p[<span class="string">'S'</span>].keys() <span class="keyword">and</span> \</span><br><span class="line">                        <span class="built_in">text</span>[t] <span class="keyword">not</span> <span class="keyword">in</span> emit_p[<span class="string">'M'</span>].keys() <span class="keyword">and</span> \</span><br><span class="line">                        <span class="built_in">text</span>[t] <span class="keyword">not</span> <span class="keyword">in</span> emit_p[<span class="string">'E'</span>].keys() <span class="keyword">and</span> \</span><br><span class="line">                        <span class="built_in">text</span>[t] <span class="keyword">not</span> <span class="keyword">in</span> emit_p[<span class="string">'B'</span>].keys()</span><br><span class="line">            <span class="keyword">for</span> y <span class="keyword">in</span> states:</span><br><span class="line">                emitP = emit_p[y].get(<span class="built_in">text</span>[t], <span class="number">0</span>) <span class="keyword">if</span> <span class="keyword">not</span> neverSeen <span class="keyword">else</span> <span class="number">1.0</span>  <span class="comment"># 设置未知字单独成词</span></span><br><span class="line">                (prob, state) = <span class="keyword">max</span>(</span><br><span class="line">                    [(V[t - <span class="number">1</span>][y0] * trans_p[y0].get(y, <span class="number">0</span>) *</span><br><span class="line">                      emitP, y0)</span><br><span class="line">                     <span class="keyword">for</span> y0 <span class="keyword">in</span> states <span class="keyword">if</span> V[t - <span class="number">1</span>][y0] &gt; <span class="number">0</span>])</span><br><span class="line">                V[t][y] = prob</span><br><span class="line">                newpath[y] = <span class="keyword">path</span>[state] + [y]</span><br><span class="line">            <span class="keyword">path</span> = newpath</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> emit_p[<span class="string">'M'</span>].get(<span class="built_in">text</span>[<span class="number">-1</span>], <span class="number">0</span>) &gt; emit_p[<span class="string">'S'</span>].get(<span class="built_in">text</span>[<span class="number">-1</span>], <span class="number">0</span>):</span><br><span class="line">            (prob, state) = <span class="keyword">max</span>([(V[<span class="keyword">len</span>(<span class="built_in">text</span>) - <span class="number">1</span>][y], y) <span class="keyword">for</span> y <span class="keyword">in</span> (<span class="string">'E'</span>, <span class="string">'M'</span>)])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            (prob, state) = <span class="keyword">max</span>([(V[<span class="keyword">len</span>(<span class="built_in">text</span>) - <span class="number">1</span>][y], y) <span class="keyword">for</span> y <span class="keyword">in</span> states])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> (prob, <span class="keyword">path</span>[state])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> cut(<span class="keyword">self</span>, <span class="built_in">text</span>):</span><br><span class="line">        <span class="keyword">import</span> os</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.load_para:</span><br><span class="line">            self.try_load_model(os.path.exists(self.model_file))</span><br><span class="line">        prob, pos_list = self.viterbi(<span class="built_in">text</span>, self.state_list, self.Pi_dic, self.A_dic, self.B_dic)</span><br><span class="line">        <span class="keyword">begin</span>, <span class="keyword">next</span> = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i, <span class="built_in">char</span> <span class="keyword">in</span> enumerate(<span class="built_in">text</span>):</span><br><span class="line">            pos = pos_list[i]</span><br><span class="line">            <span class="keyword">if</span> pos == <span class="string">'B'</span>:</span><br><span class="line">                <span class="keyword">begin</span> = i</span><br><span class="line">            elif pos == <span class="string">'E'</span>:</span><br><span class="line">                yield <span class="built_in">text</span>[<span class="keyword">begin</span>: i + <span class="number">1</span>]</span><br><span class="line">                <span class="keyword">next</span> = i + <span class="number">1</span></span><br><span class="line">            elif pos == <span class="string">'S'</span>:</span><br><span class="line">                yield <span class="built_in">char</span></span><br><span class="line">                <span class="keyword">next</span> = i + <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">next</span> &lt; <span class="keyword">len</span>(<span class="built_in">text</span>):</span><br><span class="line">            yield <span class="built_in">text</span>[<span class="keyword">next</span>:]</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    hmm = HMM()</span><br><span class="line">    hmm.train(<span class="string">'./data/trainCorpus.txt_utf8'</span>)</span><br><span class="line">    <span class="comment"># hmm.try_load_model(True)</span></span><br><span class="line">    <span class="built_in">text</span> = <span class="string">'这是一个非常棒的方案！'</span></span><br><span class="line">    <span class="keyword">while</span>(<span class="built_in">text</span> !=<span class="string">'\n'</span>):</span><br><span class="line">        res = hmm.cut(<span class="built_in">text</span>)</span><br><span class="line">        print(<span class="built_in">text</span>)</span><br><span class="line">        print(<span class="keyword">str</span>(<span class="keyword">list</span>(res)))</span><br><span class="line">        <span class="built_in">text</span>=<span class="keyword">input</span>()</span><br></pre></td></tr></table></figure>
<p><img src="/2018/10/28/隐马尔可夫模型及分词上的实现/QQ20181028-214742.png" alt="分词结果"></p>
</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>netycc</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/2018/10/28/隐马尔可夫模型及分词上的实现/">https://netycc.com/2018/10/28/隐马尔可夫模型及分词上的实现/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0 CN</a> 许可协议。转载请注明出处！</li></ul></div><br><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a class="article-share-link" data-url="https://netycc.com/2018/10/28/隐马尔可夫模型及分词上的实现/" data-id="cjnwzgbzo001rx682ds4810sn" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAN4AAADeCAAAAAB3DOFrAAACtElEQVR42u3awWorMQwF0Pz/T/fBWxVKhnslm7RwZhUmk7GPF7Ii+fWKr6//1/fP3693938+8/Nt7+68G/d148LDw8MbTf15Wvnn5E7+fPLk81Li4eHh3eO1QTkJ/e3Un0N/skng4eHh/TZekkzP0t/kDXh4eHh/kTcrW8wweSqPh4eH9yleHvrzUkW7BPlmcKXWgoeHhxfzNuH+U5+v9/fw8PDwRl31fDPI3z87lDCbLR4eHt4N3nNral943exXbWutfhEeHh7egjdr9uchvr2TbzDFpoWHh4d3iNceckrC9Cystwl0tEB4eHh4F3h5QG83hrx8kC/KbLvCw8PDO8vLD0W1zyQL1I5es/Hw8PAu8G502zcHsNoNpm224eHh4e15Z0sMbck1Wu9RWo+Hh4d3j7cvpLZBfw+of4WHh4d3lNc249sCbltKSL59Ttzx8PDwfgNvluxGwwdBP1/Q6B8DHh4e3iHeq7zyJUgCens860B/Dw8PD2/BS4qw7RIc6MIt3oOHh4d3m5fDkm/b1tTsiECxHHh4eHgXeHk5NZl0Ak6S4DZ1Lv434OHh4R3izRr2m3LtLOGeLSIeHh7eWV4SXtsEN0/KkxQ836KiYgQeHh7emtcWT/Pi72z4trzbjo6Hh4d3lpeXBvLBZgl0vi3lY+Hh4eHd4LUl3f1xqM10Z8ca8PDw8E7xkhbXpj3WgttSyDCZxsPDw1vz2qJqcr+dVr2PbWrVeHh4eCPeV3k9h+9TyLZY/DZZx8PDw7vA2xcp8gNYs+MI+RGr9ogDHh4e3oaXbwZ5WbZNo9vfFm/Aw8PDu8abBeVTZdlNWoyHh4f3d3mz4mxxZGp0iAEPDw/vs7xh8/5xrFOkt+/Bw8PDu8bLm17tdE+VfduZ4OHh4d3jnWqA5cXclt22wfDw8PCu8f4BIE2mSyE6rHEAAAAASUVORK5CYII=">分享</a><div class="tags"><a href="/tags/统计学习方法/">统计学习方法</a><a href="/tags/python/">python</a><a href="/tags/NLP/">NLP</a><a href="/tags/HMM/">HMM</a><a href="/tags/CWS/">CWS</a></div><div class="post-nav"><a class="pre" href="/2018/10/31/ubuntu16-04显卡驱动安装及环境配置/">Ubuntu16.04显卡驱动安装及环境配置</a><a class="next" href="/2018/10/25/2019科大讯飞算法岗校招笔试/">2019科大讯飞算法岗校招笔试</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'true' == true ? true : false;
var verify = 'true' == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'dCzd3ozN5OlrLCT1FcrMc8D7-gzGzoHsz',
  appKey:'UmIi39gBjdh1Aria4ssShR31',
  placeholder:'欢迎讨论~',
  avatar:'identicon',
  guest_info:guest_info,
  pageSize:'10'
})</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/刷题记录/">刷题记录</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/学习笔记/">学习笔记</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术技巧/">技术技巧</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/课设记录/">课设记录</a><span class="category-list-count">2</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/ssh配置/" style="font-size: 15px;">ssh配置</a> <a href="/tags/Jekyll/" style="font-size: 15px;">Jekyll</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/统计学习方法/" style="font-size: 15px;">统计学习方法</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/笔试/" style="font-size: 15px;">笔试</a> <a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/K近邻/" style="font-size: 15px;">K近邻</a> <a href="/tags/blog/" style="font-size: 15px;">blog</a> <a href="/tags/java/" style="font-size: 15px;">java</a> <a href="/tags/决策树/" style="font-size: 15px;">决策树</a> <a href="/tags/朴素贝叶斯/" style="font-size: 15px;">朴素贝叶斯</a> <a href="/tags/感知机/" style="font-size: 15px;">感知机</a> <a href="/tags/NLP/" style="font-size: 15px;">NLP</a> <a href="/tags/HMM/" style="font-size: 15px;">HMM</a> <a href="/tags/CWS/" style="font-size: 15px;">CWS</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/10/31/ubuntu16-04显卡驱动安装及环境配置/">Ubuntu16.04显卡驱动安装及环境配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/28/隐马尔可夫模型及分词上的实现/">隐马尔可夫模型及分词上的实现</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/25/2019科大讯飞算法岗校招笔试/">2019科大讯飞算法岗校招笔试</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/19/决策树的原理及实现/">决策树的原理及实现</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/17/朴素贝叶斯法原理及实现/">朴素贝叶斯法原理及实现</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/16/K近邻算法的原理及实现/">K近邻算法的原理及实现</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/15/Hexo中文章的两种创建方法及加密/">Hexo中文章的两种创建方法及加密</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/14/更改hexo博客中的Mathjax引擎/">更改hexo中的Mathjax引擎</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/13/mac配置ssh免密登录腾讯云服务器/">mac配置ssh免密登录腾讯云服务器</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/10/感知机的原理及实现/">感知机的原理及实现</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://www.haomwei.com/technology/maupassant-hexo.html" title="博客模板" target="_blank">博客模板</a><ul></ul><a href="https://hyxxsfwy.github.io/2016/01/15/Hexo-Markdown-%E7%AE%80%E6%98%8E%E8%AF%AD%E6%B3%95%E6%89%8B%E5%86%8C/" title="HEXO markdown简明语法" target="_blank">HEXO markdown简明语法</a><ul></ul><a href="http://www.mohu.org/info/symbols/symbols.htm" title="mathjax使用的查阅手册" target="_blank">mathjax使用的查阅手册</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">Netycc's blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
extensions: ["tex2jax.js"],
jax: ["input/TeX", "output/HTML-CSS"],
tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: true
},
    "HTML-CSS": { fonts: ["TeX"] }
  });</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>